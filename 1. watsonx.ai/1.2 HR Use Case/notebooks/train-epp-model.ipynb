{"cells": [{"cell_type": "code", "execution_count": null, "id": "d79edea9", "metadata": {}, "outputs": [], "source": "# The code was removed by Watson Studio for sharing."}, {"cell_type": "code", "execution_count": null, "id": "30d79ada", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "markdown", "id": "08ea8c44-ee92-4cfd-91c7-c55a639d693b", "metadata": {}, "source": "# Train a simple employee promotion prediction model"}, {"cell_type": "markdown", "id": "bfbcab89", "metadata": {}, "source": "## Use Case\nThis notebook demonstrates the implementation of a Random Forest Classification model for predicting employee promotions. The focus is on leveraging model training with employee historical data for accurate predictions. Employee promotion prediction involves identifying factors that contribute to promotion decisions based on various features."}, {"cell_type": "markdown", "id": "554d6a57", "metadata": {}, "source": "## What you'll learn in this notebook\nRandom Forest Classification: Random Forest is an ensemble learning method that constructs a multitude of decision trees during training and outputs the mode of the classes (classification) or mean prediction (regression) of the individual trees for robust and accurate predictions. To help understand and implement the Random Forest algorithm for predicting employee promotions, this notebook covers the process of extracting relevant features, training the Random Forest model, and evaluating its performance in predictions."}, {"cell_type": "markdown", "id": "fbeebd8b", "metadata": {}, "source": "## Table of Contents\n\n1.  [Step 1: Load and prepare the data](#load_data)\n\n1.  [Step 2: Balance the dataset](#balance_dataset)\n\n1.  [Step 3: Data Preprocessing and Train-Test split](#process_data)\n\n1.  [Step 4: Capture model metadata for AI Governance](#capture_metadata)\n\n1.  [Step 5: Train the Random forest classfier model](#train_model)\n\n1.  [Step 6: Model Evaluation](#evaluate_data)\n\n1.  [Step 7: Save the classification model](#save_model)"}, {"cell_type": "code", "execution_count": null, "id": "a8b43b5d", "metadata": {}, "outputs": [], "source": "import os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report, f1_score, recall_score, precision_score, roc_auc_score, roc_curve, auc\nimport matplotlib.pyplot as plt"}, {"cell_type": "code", "execution_count": null, "id": "70d68ed1", "metadata": {}, "outputs": [], "source": "# The code was removed by Watson Studio for sharing."}, {"cell_type": "code", "execution_count": null, "id": "a0504c8d", "metadata": {}, "outputs": [], "source": "IBM_API_KEY=os.environ['IBM_API_KEY']"}, {"cell_type": "markdown", "id": "40c3c391", "metadata": {}, "source": "<a id=\"load_data\"></a>\n## Step 1: Load and prepare the data"}, {"cell_type": "code", "execution_count": null, "id": "ba7c6e88", "metadata": {}, "outputs": [], "source": "# Download data asset from project storage and store it in the local file system\nwslib.download_file(\"epp_train.csv\", \"epp_train.csv\")"}, {"cell_type": "code", "execution_count": null, "id": "0d3c07c0", "metadata": {}, "outputs": [], "source": "# Read data from the CSV file into a DataFrame\nemployee_data = pd.read_csv(\"epp_train.csv\")\n\n# Change the order of the columns\nemployee_data = employee_data[['employee_id', 'department', 'region', 'education', 'gender',\n       'recruitment_channel', 'no_of_trainings', 'age', 'previous_year_rating',\n       'length_of_service', 'kpis_met_above_80_percent', 'any_awards_won',\n       'avg_training_score', 'is_promoted']]\n\nemployee_data.head()"}, {"cell_type": "code", "execution_count": null, "id": "434c2fd9", "metadata": {}, "outputs": [], "source": "employee_data.shape"}, {"cell_type": "code", "execution_count": null, "id": "e8ae46ef", "metadata": {}, "outputs": [], "source": "employee_data.columns"}, {"cell_type": "code", "execution_count": null, "id": "73ccaafe", "metadata": {}, "outputs": [], "source": "employee_data = employee_data.drop(columns=[\"employee_id\", \"recruitment_channel\", \"region\"])"}, {"cell_type": "markdown", "id": "4564b675", "metadata": {}, "source": "<a id=\"balance_dataset\"></a>\n## Step 2: Balance the dataset\n\nBalancing the dataset with respect to the \"is_promoted\" variable is essential to avoid bias in the predictive model. When the dataset is imbalanced, with one class significantly outnumbering the other (e.g., promoted or not promoted employees), the model may exhibit a tendency to favor the majority class. In the context of employee promotion prediction, imbalance could lead to inaccurate predictions, especially if the majority of instances involve non-promotion."}, {"cell_type": "code", "execution_count": null, "id": "807bb6e6", "metadata": {}, "outputs": [], "source": "# Separate the two classes\nn = employee_data[employee_data['is_promoted'] == 1].count()[0]\nclass_0_data = employee_data[employee_data['is_promoted'] == 0]\nclass_1_data = employee_data[employee_data['is_promoted'] == 1]\nprint(employee_data['is_promoted'].value_counts())\n# Take 3760 samples from class 0\nclass_0_sampled = class_0_data.sample(n, random_state=42)\n\n# Combine the two classes to create a balanced dataset\nemployee_data = pd.concat([class_0_sampled, class_1_data])\nprint(employee_data['is_promoted'].value_counts())"}, {"cell_type": "code", "execution_count": null, "id": "ca9347e6", "metadata": {}, "outputs": [], "source": "employee_data.reset_index(drop=True,inplace=True)"}, {"cell_type": "markdown", "id": "7365c8ad", "metadata": {}, "source": "<a id=\"process_data\"></a>\n## Step 3: Data Preprocessing and Train-Test split\nData preprocessing, including handling missing values, encoding categorical columns, and splitting the dataset into training and test sets, with a check on the class distribution in the training data."}, {"cell_type": "code", "execution_count": null, "id": "d14eba59-ef8a-4a2b-a3f9-be9499ae8ba3", "metadata": {}, "outputs": [], "source": "# Handle missing values\nemployee_data[\"education\"].fillna(employee_data[\"education\"].mode()[0], inplace=True)\nemployee_data[\"previous_year_rating\"].fillna(1, inplace=True)\n\n# Encode categorical columns\ncategorical_columns = employee_data.select_dtypes(include=['object']).columns.tolist()\nX_encoded = pd.get_dummies(employee_data, columns=categorical_columns, drop_first=True)\n\n# Split the data into features (X) and target (y)\ny = X_encoded[\"is_promoted\"]\nX_encoded = X_encoded.drop(\"is_promoted\", axis=1)\n\n# Splitting the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n\n# Initializing a Random Forest Classifier\n# rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n# Check the class distribution in the training set\nclass_counts = y_train.value_counts()\nprint(\"Class Distribution in Training Data:\")\nprint(class_counts)\n"}, {"cell_type": "markdown", "id": "f10a4d70", "metadata": {}, "source": "<a id=\"capture_metadata\"></a>\n## Step 4: Capture model metadata for AI Governance\nCollect the model metadata for effortless report generation using ibm ai governanance python library."}, {"cell_type": "code", "execution_count": null, "id": "67adc804", "metadata": {}, "outputs": [], "source": "#!pip3 install --upgrade ibm-aigov-facts-client  --no-cache | tail -n 1\nfrom ibm_aigov_facts_client import AIGovFactsClient"}, {"cell_type": "markdown", "id": "92ff6526", "metadata": {}, "source": "If you face problem and see error, please restart karnel, comment the pip installation of `ibm_aigov_facts_client` and proceced\n ```   24 from .utils import canonicalize_version\n---> 25 from .version import LegacyVersion, Version, parse\n     27 ParsedVersion = Union[Version, LegacyVersion]\n     28 UnparsedVersion = Union[Version, LegacyVersion, str]\n\nImportError: cannot import name 'LegacyVersion' from 'packaging.version' (/opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages/packaging/version.py)\n```"}, {"cell_type": "code", "execution_count": null, "id": "959eff11", "metadata": {}, "outputs": [], "source": "## factsheet metadata variables, the name of the deployed model\nEXPERIMENT_NAME='sap-hr-usecase-employee-promotion'"}, {"cell_type": "code", "execution_count": null, "id": "611d645a", "metadata": {}, "outputs": [], "source": "### Prepare ai factsheet meta data\n# Create a list to store ColumnInfo objects\ncolumn_info_list = []\n\n# Iterate over columns and create ColumnInfo objects\nfor column_name, dtype in zip(X_train.columns, X_train.dtypes):\n    cell = {\n        \"name\": column_name,\n        \"nullable\": True, \n        \"metadata\": {}, \n        \"type\": str(dtype)\n    }\n    column_info_list.append(cell)\n\ntraining_data_references = [\n        {\n            \"id\": EXPERIMENT_NAME,\n            \"type\": \"s3\",\n            \"connection\": {\n                \"access_key_id\": os.environ['COS_API_KEY'],\n                \"endpoint_url\": os.environ['COS_ENDPOINT_URL'],\n                \"resource_instance_id\": os.environ['COS_INSTANCE_ID']\n            },\n            \"location\": {\n                \"bucket\": \"bucket-sap-epp\",\n                \"path\": \"epp_train.csv\"\n            },\n            \"schema\": {\n                \"id\": \"training_schema\",\n                \"fields\": column_info_list\n            }\n        }\n    ]\n#training_data_references\n\ninpunt_schema = []\n\n# Iterate over columns and create ColumnInfo objects\nfor column_name, dtype in zip(X_train.columns, X_train.dtypes):\n    cell = {\n        \"feature\": column_name,\n        \"name\": column_name,\n        \"type\": str(dtype)\n    }\n    inpunt_schema.append(cell)"}, {"cell_type": "code", "execution_count": null, "id": "ea17034e", "metadata": {}, "outputs": [], "source": "## AI Govt factsheet client, using external models with manual log option, initiate client as\nfacts_client= AIGovFactsClient(api_key=IBM_API_KEY,experiment_name=EXPERIMENT_NAME,enable_autolog=False,external_model=True)\nfacts_client.assets.get_ai_usecases()"}, {"cell_type": "code", "execution_count": null, "id": "3f32d92c", "metadata": {}, "outputs": [], "source": "from ibm_aigov_facts_client.supporting_classes.factsheet_utils import DeploymentDetails,TrainingDataReference,ExternalModelSchemas, ModelDetails\n\n## Specify model details\nmodel_details = ModelDetails(\n    model_type = \"scikit-learn_1.1\"\n    ,input_type = \"object\"\n    ,algorithm = \"RandomForestClassifier\"\n    ,label_type = \"class_counts\"\n    ,label_column = \"is_promoted\"\n    ,prediction_type = \"Binary Classification\"\n    ,software_spec = \"runtime-23.1-py3.10\"\n    ,provider = \"Custom Environment\"\n    )\n\n## Specify training reference data\ntrainingdataref=TrainingDataReference(id=EXPERIMENT_NAME,\n            type = \"url\",\n            connection = {\n                \"url\": \"https://cloud.ibm.com/objectstorage/crn%3Av1%3Abluemix%3Apublic%3Acloud-object-storage%3Aglobal%3Aa%2Fe65910fa61ce9072d64902d03f3d4774%3A2d882273-f864-4224-bde6-d4a74b3143ae%3A%3A?bucket=bucket-sap-epp&bucketRegion=us-south&endpoint=s3.us-south.cloud-object-storage.appdomain.cloud&paneId=bucket_overview\",\n            },\n            location = {\n                \"bucket\": \"bucket-sap-epp\",\n                \"path\": \"epp_train.csv\",\n                \"source\": \"epp_train.csv\"\n            },\n            schema = {\n                \"id\": \"training_schema\",\n                \"fields\": column_info_list\n            })\n\n## Model deployment details\ndeployment=DeploymentDetails(identifier='http://169.46.68.130:8080/',name=EXPERIMENT_NAME,deployment_type=\"online\",scoring_endpoint=\"/v2/predict_and_log\")\n\n## input and output schema definition\nexternal_schemas=ExternalModelSchemas(input=[{\"fields\": inpunt_schema,\n   }], output=[{\"fields\": [\n        {'feature': 'is_promoted', 'name': 'is_promoted', 'type': 'uint8'}\n    ]}])"}, {"cell_type": "code", "execution_count": null, "id": "7c6f37d5", "metadata": {}, "outputs": [], "source": "## Save external model facts to watsonx.gov\n\nwatsonx_factsheet = facts_client.external_model_facts.save_external_model_asset(model_identifier=\"sap-hr-use-case\"\n                                                            ,name=EXPERIMENT_NAME\n                                                            ,description=\"SAP AI Core integration, HR promotion usecase\"\n                                                            ,deployment_details=deployment\n                                                            ,training_data_reference=trainingdataref\n                                                            ,model_details=model_details\n                                                            ,schemas=external_schemas\n                                                            )"}, {"cell_type": "markdown", "id": "6743cf0b", "metadata": {}, "source": "<a id=\"train_model\"></a>\n## Step 5: Train the Random forest classfier model\nInitialization, training, and testing of a Random Forest Classifier with balanced class weights for predicting promotions in an employee dataset"}, {"cell_type": "code", "execution_count": null, "id": "4bebb57d", "metadata": {}, "outputs": [], "source": "# Initialize a Random Forest Classifier with balanced class weights\nrf_classifier = RandomForestClassifier(n_estimators=100, random_state=100)\n\n# Training the model\nrf_classifier.fit(X_train, y_train)\n\n# Testing data prediction\ny_pred = rf_classifier.predict(X_test)\n\n# Traing data prediction\nyt_pred = rf_classifier.predict(X_train)"}, {"cell_type": "code", "execution_count": null, "id": "af85e816", "metadata": {}, "outputs": [], "source": "# List of feature columns \nX_encoded.columns"}, {"cell_type": "markdown", "id": "5bcf2209", "metadata": {}, "source": "<a id=\"evaluate_data\"></a>\n## Step 6: Model Evaluation\nEvaluating the training and testing accuracy scores of a Random Forest Classifier for employee promotion prediction."}, {"cell_type": "code", "execution_count": null, "id": "4af14343", "metadata": {}, "outputs": [], "source": "# Calculating accuracy\ntrain_accuracy = accuracy_score(y_train, yt_pred)\n\nprint(\"train_accuracy\",train_accuracy)\n\ntest_accuracy = accuracy_score(y_test, y_pred)\n\nprint(\"test_accuracy\",test_accuracy)"}, {"cell_type": "code", "execution_count": null, "id": "d0e6be2f", "metadata": {}, "outputs": [], "source": "#testing data \npred_df={'no_of_trainings': {0: 1,\n  1: 1,\n  2: 1,\n  3: 2,\n  4: 1,\n  5: 2,\n  6: 1,\n  7: 1,\n  8: 1,\n  9: 1},\n 'age': {0: 35, 1: 30, 2: 34, 3: 39, 4: 45, 5: 31, 6: 31, 7: 33, 8: 28, 9: 32},\n 'previous_year_rating': {0: 5.0,\n  1: 5.0,\n  2: 3.0,\n  3: 1.0,\n  4: 3.0,\n  5: 3.0,\n  6: 3.0,\n  7: 3.0,\n  8: 4.0,\n  9: 5.0},\n 'length_of_service': {0: 8,\n  1: 4,\n  2: 7,\n  3: 10,\n  4: 2,\n  5: 7,\n  6: 5,\n  7: 6,\n  8: 5,\n  9: 5},\n 'kpis_met_above_80_percent': {0: 1, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 1},\n 'any_awards_won': {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0},\n 'avg_training_score': {0: 49,\n  1: 60,\n  2: 50,\n  3: 50,\n  4: 73,\n  5: 85,\n  6: 59,\n  7: 63,\n  8: 83,\n  9: 54},\n 'department_Finance': {0: 0,\n  1: 0,\n  2: 0,\n  3: 0,\n  4: 0,\n  5: 0,\n  6: 0,\n  7: 0,\n  8: 0,\n  9: 0},\n 'department_HR': {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0},\n 'department_Legal': {0: 0,\n  1: 0,\n  2: 0,\n  3: 0,\n  4: 0,\n  5: 0,\n  6: 0,\n  7: 0,\n  8: 0,\n  9: 0},\n 'department_Operations': {0: 0,\n  1: 1,\n  2: 0,\n  3: 0,\n  4: 0,\n  5: 0,\n  6: 1,\n  7: 1,\n  8: 0,\n  9: 0},\n 'department_Procurement': {0: 0,\n  1: 0,\n  2: 0,\n  3: 0,\n  4: 0,\n  5: 0,\n  6: 0,\n  7: 0,\n  8: 0,\n  9: 0},\n 'department_R&D': {0: 0,\n  1: 0,\n  2: 0,\n  3: 0,\n  4: 0,\n  5: 0,\n  6: 0,\n  7: 0,\n  8: 0,\n  9: 0},\n 'department_Sales & Marketing': {0: 1,\n  1: 0,\n  2: 1,\n  3: 1,\n  4: 0,\n  5: 0,\n  6: 0,\n  7: 0,\n  8: 0,\n  9: 1},\n 'department_Technology': {0: 0,\n  1: 0,\n  2: 0,\n  3: 0,\n  4: 1,\n  5: 0,\n  6: 0,\n  7: 0,\n  8: 0,\n  9: 0},\n 'education_Below Secondary': {0: 0,\n  1: 0,\n  2: 0,\n  3: 0,\n  4: 0,\n  5: 0,\n  6: 0,\n  7: 0,\n  8: 0,\n  9: 0},\n \"education_Master's & above\": {0: 1,\n  1: 0,\n  2: 0,\n  3: 0,\n  4: 0,\n  5: 0,\n  6: 0,\n  7: 1,\n  8: 0,\n  9: 1},\n 'gender_m': {0: 0, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 0, 7: 1, 8: 1, 9: 1}}\npred_df=pd.DataFrame(pred_df)\n# pred_df"}, {"cell_type": "code", "execution_count": null, "id": "a8573589", "metadata": {}, "outputs": [], "source": "y_prob = rf_classifier.predict_proba(pred_df)\ny_prob"}, {"cell_type": "code", "execution_count": null, "id": "b408b0f8", "metadata": {}, "outputs": [], "source": "from sklearn.metrics import precision_score, recall_score, f1_score\n# Compute precision\nprecision = precision_score(y_test, y_pred)\nprint(precision)\n\n# Compute recall\nrecall = recall_score(y_test, y_pred)\nprint(recall)\n\n# Compute F1-score\nf1 = f1_score(y_test, y_pred)\nprint(f1)"}, {"cell_type": "code", "execution_count": null, "id": "bd813830", "metadata": {}, "outputs": [], "source": "# Get predicted probabilities for class 1\ny_prob = rf_classifier.predict_proba(X_test)[:, 1]\n\n# custom_threshold = 0.4  # You can adjust this value\n# y_pred = (y_prob >= custom_threshold).astype(int)\n\n# Classification Report\nclass_report = classification_report(y_test, y_pred)\nprint(\"Classification Report:\")\nprint(class_report)\n\n# F1 Score\nf1 = f1_score(y_test, y_pred)\nprint(f\"F1 Score: {f1:.2f}\")\n\n# Recall\nrecall = recall_score(y_test, y_pred)\nprint(f\"Recall: {recall:.2f}\")\n\n# Precision\nprecision = precision_score(y_test, y_pred)\nprint(f\"Precision: {precision:.2f}\")\n\n# AUC Score\nauc_score = roc_auc_score(y_test, y_prob)\nprint(f\"AUC Score: {auc_score:.2f}\")\n\n# ROC Curve\nfpr, tpr, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(fpr, tpr)\n\n# Plot ROC curve\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()"}, {"cell_type": "markdown", "id": "df3abb9e-a0f4-4d31-811d-88162973f303", "metadata": {}, "source": "<a id=\"save_model\"></a>\n## Step 7: Save the model as pickle\nSaving a trained Random Forest Classifier model to a file and uploading it as a project asset for future use."}, {"cell_type": "code", "execution_count": null, "id": "c3ed985a-d6f1-42e6-b956-cb5238eaef96", "metadata": {}, "outputs": [], "source": "import joblib\n\n# Save the model to a file\njoblib.dump(rf_classifier, 'epp_model_rf_nw.pkl')\n\n# Load the model from the file\nloaded_model = joblib.load('epp_model_rf_nw.pkl')\n\n# Upload the model \nwslib.upload_file(file_path=\"epp_model_rf_nw.pkl\", asset_name=\"epp_model_rf_nw.pkl\", overwrite=True)"}, {"cell_type": "code", "execution_count": null, "id": "3c46d5af", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3.10", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.13"}}, "nbformat": 4, "nbformat_minor": 5}